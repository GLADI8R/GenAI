{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467b66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing_extensions import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "from typing_extensions import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain_community.tools import QuerySQLDatabaseTool\n",
    "  \n",
    "\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from typing_extensions import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "import urllib.parse\n",
    "# from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "# from PIL import Image\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "config_memory = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# ----------------------------\n",
    "# 1. Define Tools\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "database = \"demo\"\n",
    "# database=\"AdventureWorks\"\n",
    "table = \"dbo.orders\"\n",
    "# table = \"SalesLT.Product\"\n",
    "username = \"demo_user\"\n",
    "password = \"demo123\"\n",
    "server = r\"LAPTOP-QSH9GD6T\\SQLEXPRESS\"\n",
    "\n",
    "conn_str = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+11+for+SQL+Server\"\n",
    "\n",
    "# db = SQLDatabase.from_uri(conn_str)\n",
    "\n",
    "# Tool to query SQL Server\n",
    "# query_sql_tool = QuerySQLDataBaseTool(db=db)\n",
    "                 \n",
    "# --------------- üå¶Ô∏è Weather Tool ---------------\n",
    "\n",
    "# weather = OpenWeatherMapAPIWrapper(openweathermap_api_key =\"f422746dad79b71d0156b746d847888b\")\n",
    "\n",
    "# --------------- üß† LLM ----------------\n",
    "sys.path.append(os.path.abspath('C:\\genai\\Code\\stremlit')) \n",
    "# import main_class\n",
    "# model = main_class.model()\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\"),\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    "    # timeout=None\n",
    ")\n",
    "\n",
    "# weather = OpenWeatherMapAPIWrapper(openweathermap_api_key=OPENWEATHER_API_KEY)\n",
    "# class State(BaseModel ):  # <--- add total=False This tells Python and Pydantic that not all fields are required, so you can pass partial state dictionaries without validation errors.\n",
    "#     messages: Annotated[list, add_messages]\n",
    "#     question: str\n",
    "#     query: str\n",
    "#     result: str\n",
    "#     answer: str  \n",
    "#     intent : str \n",
    "#     input_value : str\n",
    "\n",
    "\n",
    "class State(TypedDict , total=False ):  # <--- add total=False This tells Python and Pydantic that not all fields are required, so you can pass partial state dictionaries without validation errors.\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str  \n",
    "    output : str\n",
    "    chart_type : str\n",
    "    from_query : bool\n",
    "\n",
    "def ensure_ai_message(state):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not any(isinstance(m, AIMessage) for m in messages):\n",
    "        messages = [AIMessage(content=\"\")] + messages\n",
    "    state[\"messages\"] = messages\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def get_weather(state: State):\n",
    "    \"\"\" get the city name from prompt or message \"\"\"\n",
    "    print(\" debug :  get the city name from prompt or message \")\n",
    "    \n",
    "    user_input = state[\"messages\"][-1].content\n",
    "    print(f\"***get_weather   user input **{user_input}* \")\n",
    "    \n",
    "    res = llm.invoke([\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        You are given a question and must extract the city name from it.\n",
    "        Respond ONLY with the city name. If no city is found, respond with an empty string.\n",
    "        Question: {user_input}\n",
    "        \"\"\")\n",
    "        ])\n",
    "    city_name = res.content.strip()\n",
    "    # if not city_name:\n",
    "        # return {\"messages\": [AIMessage(content=\"I couldn't find a city name in your question.\")]}\n",
    "    # return {\"messages\": [AIMessage(content=f\"Extracted city: {city_name}\")], \"city\": city_name}\n",
    "    \"\"\"Get current weather for a given city.\"\"\"\n",
    "    print(f\"üö® get_weather DEBUG: state = {city_name}\")\n",
    "    return weather.run(city_name)\n",
    "\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def fetch_table_data(table: str) -> str:\n",
    "#     \"\"\"Fetch table data from the database.\"\"\"\n",
    "#     db = SQLDatabase.from_uri(DB_URI)\n",
    "#     query = f\"SELECT * FROM {table} LIMIT 100\"\n",
    "#     result = db.run(query)\n",
    "#     return result\n",
    "\n",
    "\n",
    "def get_db_connection(server, database, username, password):\n",
    "    \"\"\"\n",
    "    Connect to the SQL Server database using the provided credentials.\n",
    "    \"\"\"\n",
    "    conn_str = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+11+for+SQL+Server\"\n",
    "\n",
    "    # Create a SQLAlchemy engine\n",
    "    db2_conn = SQLDatabase.from_uri(conn_str)\n",
    "    return db2_conn\n",
    "\n",
    "system_message = \"\"\"\n",
    "Given an input question, create a syntactically correct MongoDB query to\n",
    "run to help find the answer. Unless the user specifies in his question a\n",
    "specific number of examples they wish to obtain, always limit your query to\n",
    "at most {top_k} results. You can order the results by a relevant column to\n",
    "return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for a the\n",
    "few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema\n",
    "description. Be careful to not query for columns that do not exist. Also,\n",
    "pay attention to which column is in which table.\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Question: {input}\"\n",
    "\n",
    "\n",
    "query_prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
    ")\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid MongoDB query.\"]\n",
    "\n",
    "# classification_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"Classify the user intent into one of: ['weather', 'database', 'other'].\"),\n",
    "#     (\"human\", \"User message: {input}\")\n",
    "# ])\n",
    "\n",
    "classification_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that classifies user input into one of these categories: 'weather', 'database', 'chart' or 'other'. Respond ONLY with one of these words. Do not explain.\"),\n",
    "    (\"human\", \"User: What's the weather in Delhi?\"),\n",
    "    (\"ai\", \"weather\"),\n",
    "    (\"human\", \"User: Count the number of customers from table Customer\"),\n",
    "    (\"ai\", \"database\"),\n",
    "    (\"human\", \"User: create a chart or grapgh\"),\n",
    "    (\"ai\", \"chart\"),        \n",
    "    (\"human\", \"User: Tell me a joke\"),\n",
    "    (\"ai\", \"other\"),\n",
    "    (\"human\", \"User: {input}\")\n",
    "])\n",
    "\n",
    "\n",
    "def detect_intent(user_input: str) -> str:\n",
    "    try:\n",
    "        prompt = classification_prompt.invoke({\"input\": user_input},config=config_memory)\n",
    "        result = llm.invoke(prompt ,config=config_memory)\n",
    "        print(f\"result ** {result}\")\n",
    "        # return result.content.strip().lower()\n",
    "        intent = result.content.strip().lower()\n",
    "        print(f\" ********* detect_intent  intent value is **{intent}**   \")\n",
    "        if intent not in [\"weather\", \"database\", \"chart\"]:\n",
    "            return \"other\"\n",
    "        return intent\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Intent detection failed:\", e)\n",
    "        return \"other\"\n",
    "\n",
    "from langchain_mongodb.agent_toolkit import MongoDBDatabase\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def create_mongo_agent():\n",
    "    client = MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "    db = MongoDBDatabase(client=client, database=\"sales\")\n",
    "    return db\n",
    "\n",
    "def write_query(state: State) -> dict:\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    print(f\" üö® DEBUG write_query {state.get('question')}\" )\n",
    "    try:\n",
    "        db = create_mongo_agent()\n",
    "        question = state.get(\"question\")\n",
    "        if not question:\n",
    "            messages = state.get(\"messages\", [])\n",
    "            if messages and isinstance(messages[-1], HumanMessage):\n",
    "                question = messages[-1].content\n",
    "            # else:\n",
    "            #     question = \"\"\n",
    "\n",
    "        prompt = query_prompt_template.invoke(\n",
    "            {\n",
    "                \"top_k\": 10,\n",
    "                \"table_info\": db.get_context(),\n",
    "                \"input\": question,   ##state[\"question\"]\n",
    "            },config=config_memory\n",
    "        )\n",
    "        structured_llm = llm.with_structured_output(QueryOutput)\n",
    "        result = structured_llm.invoke(prompt,config=config_memory)\n",
    "        print(\"Generated Query:\", result[\"query\"])\n",
    "        return {\"query\": result[\"query\"]}\n",
    "    except Exception as e:\n",
    "        print(\"write_query failed:\", e)\n",
    "        return {\"query\": \"\"}\n",
    "\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    print(\" üö® DEBUG execute_query \")\n",
    "    db = create_mongo_agent()\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db ,description = '\\n    Execute a SQL query against the database and get back the result..\\n    If the query is not correct, an error message will be returned.\\n    If an error is returned, rewrite the query, check the query, and try again.\\n    ')\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"],config=config_memory)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    try:\n",
    "        print(\"üö® DEBUG: generate_answer called\")\n",
    "        question = state.get(\"question\", \"\")\n",
    "        query = state.get(\"query\", \"\")\n",
    "        result = state.get(\"result\", \"\")\n",
    "        \n",
    "\n",
    "        if not (question and query and result):\n",
    "            raise ValueError(\"Missing input for generate_answer\")\n",
    "\n",
    "        prompt = (\n",
    "            \"Given the following user question, corresponding SQL query, \"\n",
    "            \"and SQL result, answer the user question.\\n\\n\"\n",
    "            f'Question: {question}\\n'\n",
    "            f'SQL Query: {query}\\n'\n",
    "            f'SQL Result: {result}'\n",
    "        )\n",
    "\n",
    "        response = llm.invoke(prompt,config=config_memory)\n",
    "        print(\"‚úÖ Answer Generated:\", response.content)\n",
    "        return {\"output\": response.content}\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå ERROR in generate_answer:\", e)\n",
    "        return {\"answer\": \"An error occurred while generating the answer.\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. State Setup\n",
    "# ----------------------------\n",
    "\n",
    "# class State(dict):\n",
    "#     pass\n",
    "\n",
    "\n",
    "def route(state: State) -> dict:\n",
    "    \n",
    "    print(\"** DEBUG  route(state: State) : ** \", state)\n",
    "\n",
    "\n",
    "    messages = state.get(\"messages\", [])\n",
    "\n",
    "    if not any(isinstance(m, AIMessage) for m in messages):\n",
    "        messages = [AIMessage(content=\"\")] + messages\n",
    "        \n",
    "    if messages and isinstance(messages[-1], HumanMessage):\n",
    "        user_input = messages[-1].content.strip().lower()\n",
    "    else:\n",
    "        user_input = \"default\"\n",
    "\n",
    "    intent = detect_intent(user_input).strip().lower()        \n",
    "    print(f\"[Router] input = {user_input}\")\n",
    "\n",
    "    print(f\"  ***   outside the if condition func route   intent value is   *{intent}*\")\n",
    "    \n",
    "    if  \"weather\" in intent:\n",
    "        print(f\"üå¶Ô∏è Route: weather_node  message **{messages} **\")\n",
    "        return {\"next\": \"weather_node\", \"messages\": user_input}\n",
    "    elif any(k in user_input for k in [\"table\", \"database\", \"query\", \"sql\", \"data\", \"record\", \"column\"]):     ###intent == \"database\":\n",
    "        print(\"üìä Route: table_node\")\n",
    "        return {\"next\": \"table_node\", \"messages\": messages, \"question\": user_input}\n",
    "    elif \"chart\" in intent:\n",
    "        print(\"üìä Route: chart_node\")\n",
    "        return {\"next\": \"chart_node\", \"messages\": user_input}\n",
    "    else:\n",
    "        print(\"‚ùì Route: default\")\n",
    "        return {\"next\": \"default\", \"messages\": messages}    \n",
    "    \n",
    "\n",
    "\n",
    "def table_tool_node(state: State) -> State:\n",
    "    print(\"üö® Entered table_tool_node\")\n",
    "\n",
    "    # Step 1: Write SQL query\n",
    "    result1 = write_query(state)\n",
    "    state.update(result1)\n",
    "    print(\"‚úÖ write_query output:\", result1)\n",
    "\n",
    "    # Step 2: Execute SQL query\n",
    "    result2 = execute_query(state)\n",
    "    state.update(result2)\n",
    "    print(\"‚úÖ execute_query output:\", result2)\n",
    "\n",
    "    # Add to messages for UI\n",
    "    \n",
    "    # chart_type = get_chart_type(state.get('question'))\n",
    "    # if chart_type:  \n",
    "    #     # state[\"messages\"].append(AIMessage(content=f\"Chart type detected: {chart_type}\"))\n",
    "    #     state[\"chart_type\"] = chart_type\n",
    "    #     print(f\"üö® chart_type detected: {chart_type}\")  \n",
    "    state[\"from_query\"] = True\n",
    "    #     create_chart(state) \n",
    "    # else:\n",
    "    # Step 3: Generate final answer\n",
    "    result3 = generate_answer(state)\n",
    "    state.update(result3)\n",
    "    print(\"‚úÖ generate_answer output:\", result3)        \n",
    "    \n",
    "    state[\"messages\"] = state.get(\"messages\", []) + [AIMessage(content=state.get(\"answer\", \"No answer\"))]\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_chart_type(state: State):\n",
    "    \"\"\" get the chart type from prompt or message \"\"\"\n",
    "    print(\" debug :  get the chart type from prompt or message  \")\n",
    "    question = state.get(\"question\", \"\")\n",
    "    query = state.get(\"query\", \"\")\n",
    "    result = state.get(\"result\", \"\")\n",
    "    print(f\"***get_chart_type   question **{question}* \")\n",
    "    print(f\"***get_chart_type   query **{query}* \")     \n",
    "    print(f\"***get_chart_type   result **{result}* \")\n",
    "\n",
    "    \n",
    "\n",
    "    user_input = state[\"messages\"][-1].content\n",
    "    print(f\"***get_chart_type   user input **{user_input}* \")\n",
    "\n",
    "\n",
    "\n",
    "    res = llm.invoke([\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        1. You are a helpful assistant that extracts the chart type from user input.\n",
    "        2. You will be given a question and must extract the visualization type from it.                         \n",
    "        3. Respond ONLY with the visualization type. If no visualization is found, respond with an empty string.\n",
    "        4. The visualization types can be: 'bar', 'line', 'scatter', 'pie', 'histogram', 'boxplot', 'heatmap', 'area', 'donut', 'radar', 'funnel', 'treemap', or 'wordcloud'.\n",
    "        5. If the question does not specify a visualization type, respond with an empty string  \n",
    "        Question: {question}\n",
    "        \"\"\")\n",
    "        ])\n",
    "    chart_name = res.content.strip()\n",
    "    state[\"chart_type\"] = chart_name\n",
    "    print(f\"üö® get_chart_type DEBUG: state = {chart_name}\")\n",
    "   \n",
    "    return {\"chart_type\" :chart_name }\n",
    "\n",
    "def create_chart(state :State) :\n",
    "    \"\"\"Create a chart or graph using the dataframe result set\"\"\"\n",
    "    # user_input = state[\"messages\"][-1].content\n",
    "    # chart_type = get_chart_type(state.get('question'))\n",
    "\n",
    "    chart_type = get_chart_type(state)\n",
    "    print(f'Create a chart or graph using the dataframe result set **{state[\"from_query\"] }**')\n",
    "\n",
    "    print(\"************************************************\")\n",
    "    question = state.get(\"question\", \"\")\n",
    "    query = state.get(\"query\", \"\")\n",
    "    result = state.get(\"result\", \"\")\n",
    "    print(f\"***get_chart_type   question **{question}* \")\n",
    "    print(f\"***get_chart_type   query **{query}* \")     \n",
    "    print(f\"***get_chart_type   result **{result}* \")\n",
    "    print(\"************************************************\")    \n",
    "    if state[\"from_query\"] :\n",
    "        print(\"üö® create_chart called with from_query set to True. Proceeding with chart creation.\")\n",
    "        df = pd.read_sql(state.get(\"query\", \"\"),  db._engine.connect()  )\n",
    "        df_columns =df.columns\n",
    "        \n",
    "        \n",
    "        df.plot(kind=state[\"chart_type\"], x=df_columns[0], y=df_columns[1])   \n",
    "    else:\n",
    "        print(\"üö® create_chart called without from_query set to True. Skipping chart creation.\")\n",
    "        # chart_type = get_chart_type(state)\n",
    "    if not chart_type:  \n",
    "        print(\"‚ùå No chart type found in state.\")\n",
    "        return {\"output\": \"No chart type specified.\"}\n",
    "    print(f\"üö® Entered create_chart {chart_type}\")\n",
    "    return \n",
    "\n",
    "def is_chart_request(user_input: str) -> bool:\n",
    "    return bool(re.search(r\"\\b(chart|graph|plot|visualize)\\b\", user_input.lower()))\n",
    "\n",
    "\n",
    "weather_tool = RunnableLambda(lambda state: {\"output\": get_weather(state)})\n",
    "chart_tool = RunnableLambda(lambda state: {\"output\": create_chart(state)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25120cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def default_response(state: State) -> dict:\n",
    "#     return {\"output\": \"Please ask about a table or a city for weather.\"}\n",
    "\n",
    "def default_response(state: State) -> State:\n",
    "    # return {\"messages\": [model.invoke(state[\"messages\"])]}\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"],config=config_memory)] }\n",
    "# ----------------------------\n",
    "# 4. LangGraph Creation\n",
    "# ----------------------------\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"router\", route)\n",
    "graph.add_node(\"weather_tool\", weather_tool)\n",
    "graph.add_node(\"create_chart\", chart_tool)\n",
    "\n",
    "graph.add_node(\"table_tool\", table_tool_node)\n",
    "\n",
    "graph.add_node(\"default\", default_response)\n",
    "\n",
    "graph.set_entry_point(\"router\")\n",
    "# graph.add_conditional_edges(\n",
    "#     \"router\", lambda state: route(state),\n",
    "#     {\n",
    "#         \"weather_tool\": \"weather_tool\",\n",
    "#         \"table_tool\": \"table_tool\",\n",
    "#         \"default\": \"default\"\n",
    "#     }\n",
    "# )\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    # üëá key to look inside router's return value\n",
    "    lambda state: state[\"next\"],\n",
    "    path_map={\n",
    "        \"weather_node\": \"weather_tool\",\n",
    "        \"table_node\": \"table_tool\",\n",
    "        \"chart_node\" : \"create_chart\" ,\n",
    "        \"default\": \"default\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"weather_tool\", END)\n",
    "# graph.add_edge(\"table_tool\", \"create_chart\")\n",
    "graph.add_edge(\"table_tool\", \"create_chart\")\n",
    "graph.add_edge(\"default\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detect_intent(\"weather of Noida\"))         # üëâ Should return \"weather\"\n",
    "# print(detect_intent(\"show product data\"))        # üëâ Should return \"database\"\n",
    "# print(detect_intent(\"who is elon musk\"))         # üëâ Should return \"other\"\n",
    "print(detect_intent(\"using customer tables create line chart\"))         # üëâ Should return \"other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0606b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** DEBUG  route(state: State) : **  {'messages': [HumanMessage(content=\"generate only query to find the user ids of top 10 users with highest total purchase amount (quantity * price) from 'orders' collection?\", additional_kwargs={}, response_metadata={}, id='1b3a47d2-21d2-464b-b8e7-324337cfe419')]}\n",
      "result ** content='database' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 151, 'total_tokens': 153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BzN7QZrepDRGw13W6R4mEQgFyZuZ6', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--619ad48e-23b5-4e0b-93ba-9e6776e351bf-0' usage_metadata={'input_tokens': 151, 'output_tokens': 2, 'total_tokens': 153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      " ********* detect_intent  intent value is **database**   \n",
      "[Router] input = generate only query to find the user ids of top 10 users with highest total purchase amount (quantity * price) from 'orders' collection?\n",
      "  ***   outside the if condition func route   intent value is   *database*\n",
      "üìä Route: table_node\n",
      "üö® Entered table_tool_node\n",
      " üö® DEBUG write_query generate only query to find the user ids of top 10 users with highest total purchase amount (quantity * price) from 'orders' collection?\n",
      "Generated Query: db.orders.aggregate([\n",
      "  {\n",
      "    $group: {\n",
      "      _id: \"$user_id\",\n",
      "      total_purchase: { $sum: { $multiply: [\"$quantity\", \"$price\"] } }\n",
      "    }\n",
      "  },\n",
      "  { $sort: { total_purchase: -1 } },\n",
      "  { $limit: 10 },\n",
      "  { $project: { _id: 0, user_id: \"$_id\" } }\n",
      "])\n",
      "‚úÖ write_query output: {'query': 'db.orders.aggregate([\\n  {\\n    $group: {\\n      _id: \"$user_id\",\\n      total_purchase: { $sum: { $multiply: [\"$quantity\", \"$price\"] } }\\n    }\\n  },\\n  { $sort: { total_purchase: -1 } },\\n  { $limit: 10 },\\n  { $project: { _id: 0, user_id: \"$_id\" } }\\n])'}\n",
      " üö® DEBUG execute_query \n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for QuerySQLDatabaseTool\ndb\n  Input should be an instance of SQLDatabase [type=is_instance_of, input_value=<langchain_mongodb.agent_...bject at 0x762a644d4c70>, input_type=MongoDBDatabase]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerate only query to find the user ids of top 10 users with highest total purchase amount (quantity * price) from \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m collection?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print(result.get(\"output\", result))\u001b[39;00m\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langgraph/pregel/main.py:3019\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[0m\n\u001b[1;32m   3016\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3017\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3019\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3021\u001b[0m     config,\n\u001b[1;32m   3022\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3023\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3025\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3026\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3027\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3028\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3029\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3030\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3031\u001b[0m ):\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3033\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langgraph/pregel/main.py:2651\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2650\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2651\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2652\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2653\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2654\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2655\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2656\u001b[0m ):\n\u001b[1;32m   2657\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2658\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2659\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2660\u001b[0m     )\n\u001b[1;32m   2661\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langgraph/pregel/_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langgraph/pregel/_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:646\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 646\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:390\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[13], line 346\u001b[0m, in \u001b[0;36mtable_tool_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ write_query output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result1)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Step 2: Execute SQL query\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m result2 \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m state\u001b[38;5;241m.\u001b[39mupdate(result2)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ execute_query output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result2)\n",
      "Cell \u001b[0;32mIn[13], line 258\u001b[0m, in \u001b[0;36mexecute_query\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m üö® DEBUG execute_query \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m db \u001b[38;5;241m=\u001b[39m create_mongo_agent()\n\u001b[0;32m--> 258\u001b[0m execute_query_tool \u001b[38;5;241m=\u001b[39m \u001b[43mQuerySQLDatabaseTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    Execute a SQL query against the database and get back the result..\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    If the query is not correct, an error message will be returned.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    If an error is returned, rewrite the query, check the query, and try again.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_query_tool\u001b[38;5;241m.\u001b[39minvoke(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m],config\u001b[38;5;241m=\u001b[39mconfig_memory)}\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langchain_core/tools/base.py:516\u001b[0m, in \u001b[0;36mBaseTool.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs_schema must be a subclass of pydantic BaseModel or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma JSON schema dict. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs_schema\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_n_shit/venv/lib/python3.10/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for QuerySQLDatabaseTool\ndb\n  Input should be an instance of SQLDatabase [type=is_instance_of, input_value=<langchain_mongodb.agent_...bject at 0x762a644d4c70>, input_type=MongoDBDatabase]\n    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"generate only query to find the user ids of top 10 users with highest total purchase amount (quantity * price) from 'orders' collection?\")]\n",
    "})\n",
    "print(result)\n",
    "# print(result.get(\"output\", result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"messages\": \"weather Noida\"})\n",
    "output = result.get(\"output\")\n",
    "\n",
    "\n",
    "result = app.invoke({\"messages\": [HumanMessage(content=\"weather of Noida\")]  })\n",
    "print(result[\"output\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
